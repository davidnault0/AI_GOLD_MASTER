# Guide de D√©marrage Rapide - AI Integration

## Question: GPT-4o ou Qwen 3 pour une efficacit√© accrue?

**R√©ponse courte**: Cela d√©pend de vos besoins sp√©cifiques!

## D√©marrage en 3 √©tapes

### √âtape 1: Choisir votre mod√®le

Utilisez ce tableau de d√©cision rapide:

| Crit√®re | Recommandation |
|---------|----------------|
| Vous d√©butez | **GPT-4o** ‚úì |
| Budget limit√© initial | **GPT-4o** ‚úì |
| Qualit√© maximale | **GPT-4o** ‚úì |
| Donn√©es confidentielles | **Qwen 3** ‚úì |
| Volume √©lev√© (>1M tokens/mois) | **Qwen 3** ‚úì |
| Infrastructure GPU disponible | **Qwen 3** ‚úì |
| Latence ultra-faible requise | **Qwen 3** ‚úì |

### √âtape 2: Configuration

#### Option A: GPT-4o (Recommand√© pour d√©buter)

```bash
# 1. Copier le fichier d'environnement
cp .env.example .env

# 2. √âditer .env et ajouter votre cl√© API OpenAI
# OPENAI_API_KEY=sk-...

# 3. Tester
node ai-integration.js
```

Co√ªt: ~$2.50-10 par million de tokens

#### Option B: Qwen 3 (Pour infrastructure locale)

```bash
# 1. Installer Ollama (le plus simple)
curl -fsSL https://ollama.com/install.sh | sh

# 2. T√©l√©charger Qwen 3
ollama pull qwen2.5:7b

# 3. Lancer le serveur
ollama serve

# 4. Configurer l'endpoint
cp .env.example .env
# Modifier DEFAULT_AI_MODEL=qwen-3
```

Voir [QWEN3_DEPLOYMENT.md](./QWEN3_DEPLOYMENT.md) pour plus de d√©tails.

### √âtape 3: Utilisation

```javascript
const AIModelManager = require('./ai-integration');

// Initialiser
const ai = new AIModelManager();

// Exemple: G√©n√©rer du code Pine Script
const result = await ai.generatePineScript(
  'Cr√©er un indicateur RSI avec alertes'
);

console.log(result);
```

## Approche Hybride (Optimal)

Pour une **efficacit√© maximale**, utilisez les deux:

```javascript
// T√¢ches simples ‚Üí Qwen 3 (local, rapide, gratuit)
const localAI = new AIModelManager('qwen-3');
await localAI.analyzeLogs(logs);

// T√¢ches complexes ‚Üí GPT-4o (cloud, haute qualit√©)
const cloudAI = new AIModelManager('gpt-4o');
await cloudAI.generatePineScript('Indicateur complexe...');
```

**Avantages**:
- üí∞ √âconomies: 40-60% sur les co√ªts
- ‚ö° Vitesse: R√©ponses instantan√©es pour t√¢ches courantes
- üéØ Qualit√©: Meilleurs r√©sultats pour t√¢ches critiques

## M√©triques de Performance

### GPT-4o
- Latence: 500-2000ms
- Qualit√©: ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ (Excellente)
- Co√ªt: $2.50-10 / 1M tokens
- Setup: 5 minutes

### Qwen 3 Local
- Latence: 50-200ms
- Qualit√©: ‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ (Tr√®s bonne)
- Co√ªt: ~$0 apr√®s setup
- Setup: 30-60 minutes

## Ressources Suppl√©mentaires

- üìä [Comparaison d√©taill√©e](./AI_MODEL_COMPARISON.md)
- üöÄ [Guide d√©ploiement Qwen 3](./QWEN3_DEPLOYMENT.md)
- üìù [Documentation compl√®te](./README.md)

## Support

Pour questions ou probl√®mes, voir la documentation ou ouvrir une issue sur GitHub.

---

**Conclusion**: Commencez avec GPT-4o pour sa simplicit√©, √©valuez Qwen 3 si vos besoins √©voluent vers plus de volume ou de confidentialit√©.
